# ğŸš€ SEO Content Quality & Duplicate Detector  

### ğŸ“˜ Project Overview
This project delivers an **end-to-end AI + NLP pipeline** to evaluate webpage SEO content quality and detect near-duplicates.  
It intelligently parses HTML, extracts linguistic and structural features, computes content similarity,  
and predicts overall quality â€” **Low**, **Medium**, or **High** â€” using machine learning.  

---

## âš™ï¸ Tech Stack
**Languages:** Python 3.9+  
**Core Libraries:** `BeautifulSoup4`, `textstat`, `sentence-transformers`, `scikit-learn`, `pandas`, `nltk`  
**Interface:** Jupyter Notebook & Streamlit (for real-time analysis)  

---

## ğŸ§© Features
âœ… **HTML Parsing:** Extracts titles and main body text from raw HTML  
âœ… **Feature Engineering:** Word/sentence count, readability (Flesch), TF-IDF keywords, embeddings  
âœ… **Duplicate Detection:** Cosine similarity on embeddings or TF-IDF vectors  
âœ… **Thin Content Flagging:** Identifies low-word-count pages (<500 words)  
âœ… **Quality Scoring Model:** Random Forest classifier for SEO quality prediction  
âœ… **Real-Time Demo:** Live Streamlit app for instant URL evaluation  

---

## ğŸ§  Workflow
Input HTML/URLs â†’ Clean & Parse â†’ Extract NLP Features â†’ Detect Duplicates â†’
Train Quality Model â†’ Predict (Low / Medium / High) â†’ Real-Time Streamlit Analysis

yaml
Copy code

---

## âš™ï¸ Setup Instructions
```bash
# Clone the repository
git clone https://github.com/annavinod/seo-content-detector
cd seo-content-detector

# Install dependencies
pip install -r requirements.txt

# Launch the main notebook
jupyter notebook notebooks/seo_pipeline.ipynb
âš¡ Quick Start
python
Copy code
from utils.scorer import analyze_url

# Analyze any webpage URL in real-time
result = analyze_url("https://example.com/article")
print(result)
ğŸŒ Live Demo
ğŸ¯ Try it here: SEO Content Detector App â†’

Analyze any live webpage for readability, SEO score, and duplication â€” directly from your browser.

ğŸ“Š Model Performance
Metric	Score
Model	Random Forest Classifier
Accuracy	0.78
F1-Score	0.77
Duplicate Pairs	3
Thin Content Pages	6 (â‰ˆ10%)

ğŸ’¡ Key Design Decisions
Parsing Strategy: Focused on <p>, <article>, and <main> for core content extraction

Similarity Threshold: Cosine similarity â‰¥ 0.80 â†’ duplicate

Feature Selection: Chose readability + count features + embeddings for explainability

Model Choice: Random Forest for stability and interpretability over deep models

âš ï¸ Limitations
Pages heavy with JavaScript or structured markup may yield incomplete text extraction

Readability metrics can vary by domain type (technical vs. general audience)

Current quality labels are synthetic â€” human-labeled SEO data would improve performance

âœ… Evaluation Checklist
 End-to-end pipeline executes without errors

 Real-time analyze_url() function operational

 Streamlit app deployed & stable

 Clean modular codebase

 Well-documented and reproducible project

ğŸ Submission Summary
Status: âœ”ï¸ Complete & Deployed
Bonus: Streamlit Cloud Deployment Achieved
Author: Anna Vinod
Live Demo: seo-content-detector-9wgjet3hafdemayusgyn9j.streamlit.app

â€œData is the new SEO â€” structured, measurable, and intelligent.â€ ğŸŒâœ¨
